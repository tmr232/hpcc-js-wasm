import{_ as a,c as s,o as e,a2 as i}from"./chunks/framework.DdIfLAqJ.js";const g=JSON.parse('{"title":"Class: Llama","description":"","frontmatter":{},"headers":[],"relativePath":"llama/src/llama/classes/Llama.md","filePath":"llama/src/llama/classes/Llama.md","lastUpdated":null}'),t={name:"llama/src/llama/classes/Llama.md"},l=i(`<p><a href="/hpcc-js-wasm/README.html"><strong>@hpcc-js/wasm-root</strong></a> • <strong>Docs</strong></p><hr><h1 id="class-llama" tabindex="-1">Class: Llama <a class="header-anchor" href="#class-llama" aria-label="Permalink to &quot;Class: Llama&quot;">​</a></h1><p>The llama WASM library, provides a simplified wrapper around the llama.cpp library.</p><p>See <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noreferrer">llama.cpp</a> for more details.</p><div class="language-ts vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">ts</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> { Llama, WebBlob } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;@hpcc-js/wasm-llama&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">let</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> llama </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Llama.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">load</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;https://huggingface.co/CompendiumLabs/bge-base-en-v1.5-gguf/resolve/main/bge-base-en-v1.5-q4_k_m.gguf&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> webBlob</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> Blob</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> WebBlob.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">create</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">new</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> URL</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model));</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> data</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> ArrayBuffer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> webBlob.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">arrayBuffer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> embeddings</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> llama.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">embedding</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Hello and Welcome!&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">new</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> Uint8Array</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data));</span></span></code></pre></div><h2 id="methods" tabindex="-1">Methods <a class="header-anchor" href="#methods" aria-label="Permalink to &quot;Methods&quot;">​</a></h2><h3 id="load" tabindex="-1">load() <a class="header-anchor" href="#load" aria-label="Permalink to &quot;load()&quot;">​</a></h3><blockquote><p><code>static</code> <strong>load</strong>(): <code>Promise</code>&lt;<a href="/hpcc-js-wasm/llama/src/llama/classes/Llama.html"><code>Llama</code></a>&gt;</p></blockquote><p>Compiles and instantiates the raw wasm.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>In general WebAssembly compilation is disallowed on the main thread if the buffer size is larger than 4KB, hence forcing <code>load</code> to be asynchronous;</p></div><h4 id="returns" tabindex="-1">Returns <a class="header-anchor" href="#returns" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><p><code>Promise</code>&lt;<a href="/hpcc-js-wasm/llama/src/llama/classes/Llama.html"><code>Llama</code></a>&gt;</p><p>A promise to an instance of the Llama class.</p><h4 id="defined-in" tabindex="-1">Defined in <a class="header-anchor" href="#defined-in" aria-label="Permalink to &quot;Defined in&quot;">​</a></h4><p><a href="https://github.com/hpcc-systems/hpcc-js-wasm/blob/15665b1fde66796592c6046fea63dded1efe25f7/packages/llama/src/llama.ts#L41" target="_blank" rel="noreferrer">llama/src/llama.ts:41</a></p><hr><h3 id="unload" tabindex="-1">unload() <a class="header-anchor" href="#unload" aria-label="Permalink to &quot;unload()&quot;">​</a></h3><blockquote><p><code>static</code> <strong>unload</strong>(): <code>void</code></p></blockquote><p>Unloades the compiled wasm instance.</p><h4 id="returns-1" tabindex="-1">Returns <a class="header-anchor" href="#returns-1" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><p><code>void</code></p><h4 id="defined-in-1" tabindex="-1">Defined in <a class="header-anchor" href="#defined-in-1" aria-label="Permalink to &quot;Defined in&quot;">​</a></h4><p><a href="https://github.com/hpcc-systems/hpcc-js-wasm/blob/15665b1fde66796592c6046fea63dded1efe25f7/packages/llama/src/llama.ts#L50" target="_blank" rel="noreferrer">llama/src/llama.ts:50</a></p><hr><h3 id="version" tabindex="-1">version() <a class="header-anchor" href="#version" aria-label="Permalink to &quot;version()&quot;">​</a></h3><blockquote><p><strong>version</strong>(): <code>string</code></p></blockquote><h4 id="returns-2" tabindex="-1">Returns <a class="header-anchor" href="#returns-2" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><p><code>string</code></p><p>The Llama c++ version</p><h4 id="defined-in-2" tabindex="-1">Defined in <a class="header-anchor" href="#defined-in-2" aria-label="Permalink to &quot;Defined in&quot;">​</a></h4><p><a href="https://github.com/hpcc-systems/hpcc-js-wasm/blob/15665b1fde66796592c6046fea63dded1efe25f7/packages/llama/src/llama.ts#L57" target="_blank" rel="noreferrer">llama/src/llama.ts:57</a></p><hr><h3 id="embedding" tabindex="-1">embedding() <a class="header-anchor" href="#embedding" aria-label="Permalink to &quot;embedding()&quot;">​</a></h3><blockquote><p><strong>embedding</strong>(<code>text</code>, <code>model</code>, <code>format</code>): <code>number</code>[][]</p></blockquote><p>Calculates the vector representation of the input text.</p><h4 id="parameters" tabindex="-1">Parameters <a class="header-anchor" href="#parameters" aria-label="Permalink to &quot;Parameters&quot;">​</a></h4><p>• <strong>text</strong>: <code>string</code></p><p>The input text.</p><p>• <strong>model</strong>: <code>Uint8Array</code></p><p>The model to use for the embedding.</p><p>• <strong>format</strong>: <code>string</code> = <code>&quot;array&quot;</code></p><h4 id="returns-3" tabindex="-1">Returns <a class="header-anchor" href="#returns-3" aria-label="Permalink to &quot;Returns&quot;">​</a></h4><p><code>number</code>[][]</p><p>The embedding of the text using the model.</p><h4 id="defined-in-3" tabindex="-1">Defined in <a class="header-anchor" href="#defined-in-3" aria-label="Permalink to &quot;Defined in&quot;">​</a></h4><p><a href="https://github.com/hpcc-systems/hpcc-js-wasm/blob/15665b1fde66796592c6046fea63dded1efe25f7/packages/llama/src/llama.ts#L69" target="_blank" rel="noreferrer">llama/src/llama.ts:69</a></p>`,47),n=[l];function r(h,o,d,p,c,k){return e(),s("div",null,n)}const u=a(t,[["render",r]]);export{g as __pageData,u as default};
